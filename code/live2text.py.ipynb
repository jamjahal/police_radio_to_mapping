{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_APPLICATION_CREDENTIALS=\"/Users/allanshomefolder/keys/EmergencyLocator-4d510abe556a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\u001b[0;33m\n",
      "Listening, say \"Quit\" or \"Exit\" to stop.\n",
      "\n",
      "End (ms)       Transcript Results/Status\n",
      "=====================================================\n",
      "\u001b[0;33m\n",
      "0: NEW REQUEST\n",
      "\u001b[0;32m\u001b[K3050: check\n",
      "\u001b[0;33m\n",
      "10000: NEW REQUEST\n",
      "\u001b[0;32m\u001b[K20356: is this the right exitg\n",
      "\u001b[0;33mExiting...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Google Cloud Speech API sample application using the streaming API.\n",
    "NOTE: This module requires the dependencies `pyaudio` and `termcolor`.\n",
    "To install using pip:\n",
    "    pip install pyaudio\n",
    "    pip install termcolor\n",
    "Example usage:\n",
    "    python transcribe_streaming_infinite.py\n",
    "\"\"\"\n",
    "\n",
    "# [START speech_transcribe_infinite_streaming]\n",
    "\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# uses result_end_time currently only avaialble in v1p1beta, will be in v1 soon\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "# Return a DataFrame of transcrits \n",
    "import pandas as pd\n",
    "\n",
    "# Audio recording parameters\n",
    "STREAMING_LIMIT = 10000\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "RED = '\\033[0;31m'\n",
    "GREEN = '\\033[0;32m'\n",
    "YELLOW = '\\033[0;33m'\n",
    "\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"Return Current Time in MS.\"\"\"\n",
    "\n",
    "    return int(round(time.time() * 1000))\n",
    "\n",
    "\n",
    "class ResumableMicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self, rate, chunk_size):\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.start_time = get_current_time()\n",
    "        self.restart_counter = 0\n",
    "        self.audio_input = []\n",
    "        self.last_audio_input = []\n",
    "        self.result_end_time = 0\n",
    "        self.is_final_end_time = 0\n",
    "        self.final_request_end_time = 0\n",
    "        self.bridging_offset = 0\n",
    "        self.last_transcript_was_final = False\n",
    "        self.new_stream = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\"Stream Audio from microphone to API and to local buffer\"\"\"\n",
    "\n",
    "        while not self.closed:\n",
    "            data = []\n",
    "\n",
    "            if self.new_stream and self.last_audio_input:\n",
    "\n",
    "                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)\n",
    "\n",
    "                if chunk_time != 0:\n",
    "\n",
    "                    if self.bridging_offset < 0:\n",
    "                        self.bridging_offset = 0\n",
    "\n",
    "                    if self.bridging_offset > self.final_request_end_time:\n",
    "                        self.bridging_offset = self.final_request_end_time\n",
    "\n",
    "                    chunks_from_ms = round((self.final_request_end_time -\n",
    "                                            self.bridging_offset) / chunk_time)\n",
    "\n",
    "                    self.bridging_offset = (round((\n",
    "                        len(self.last_audio_input) - chunks_from_ms)\n",
    "                                                  * chunk_time))\n",
    "\n",
    "                    for i in range(chunks_from_ms, len(self.last_audio_input)):\n",
    "                        data.append(self.last_audio_input[i])\n",
    "\n",
    "                self.new_stream = False\n",
    "\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            self.audio_input.append(chunk)\n",
    "\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data.append(chunk)\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                    self.audio_input.append(chunk)\n",
    "\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)\n",
    "\n",
    "\n",
    "def listen_print_loop(responses, stream):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "    # set up empty list for transcripts and timestamp\n",
    "    transcripts = []\n",
    "    timestamps=[]\n",
    "    \n",
    "    for response in responses:\n",
    "\n",
    "        # setting streaming limit\n",
    "        if get_current_time() - stream.start_time > STREAMING_LIMIT:\n",
    "            stream.start_time = get_current_time()\n",
    "            break\n",
    "\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        result_seconds = 0\n",
    "        result_nanos = 0\n",
    "\n",
    "        if result.result_end_time.seconds:\n",
    "            result_seconds = result.result_end_time.seconds\n",
    "\n",
    "        if result.result_end_time.nanos:\n",
    "            result_nanos = result.result_end_time.nanos\n",
    "\n",
    "        stream.result_end_time = int((result_seconds * 1000)\n",
    "                                     + (result_nanos / 1000000))\n",
    "\n",
    "        corrected_time = (stream.result_end_time - stream.bridging_offset\n",
    "                          + (STREAMING_LIMIT * stream.restart_counter))\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "\n",
    "        if result.is_final:\n",
    "\n",
    "            sys.stdout.write(GREEN)\n",
    "            sys.stdout.write('\\033[K')\n",
    "            sys.stdout.write(str(corrected_time) + ': ' + transcript + '\\n')\n",
    "            \n",
    "            # Save Transcript to dataframe\n",
    "            transcripts.append(transcript)\n",
    "            timestamps.append(get_current_time())\n",
    "            \n",
    "\n",
    "            stream.is_final_end_time = stream.result_end_time\n",
    "            stream.last_transcript_was_final = True\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                sys.stdout.write(YELLOW)\n",
    "                sys.stdout.write('Exiting...\\n')\n",
    "                stream.closed = True\n",
    "                trans_dict = {'transcriptions': transcripts, 'timestamp': timestamps}\n",
    "                t2s_df=pd.DataFrame(trans_dict)\n",
    "                return t2s_df\n",
    "                break\n",
    "            \n",
    "         \n",
    "\n",
    "        else:\n",
    "            sys.stdout.write(RED)\n",
    "            sys.stdout.write('\\033[K')\n",
    "            sys.stdout.write(str(corrected_time) + ': ' + transcript + '\\r')\n",
    "\n",
    "            stream.last_transcript_was_final = False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"start bidirectional streaming from microphone input to speech API\"\"\"\n",
    "# check Credentials\n",
    "    client = speech.SpeechClient.from_service_account_json(GOOGLE_APPLICATION_CREDENTIALS)\n",
    "    \n",
    "    # Set Configuration\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        language_code='en-US',\n",
    "        max_alternatives=1)\n",
    "    streaming_config = speech.types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "\n",
    "    # Set input as microphone\n",
    "    mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)\n",
    "    print(mic_manager.chunk_size)\n",
    "    sys.stdout.write(YELLOW)\n",
    "    sys.stdout.write('\\nListening, say \"Quit\" or \"Exit\" to stop.\\n\\n')\n",
    "    sys.stdout.write('End (ms)       Transcript Results/Status\\n')\n",
    "    sys.stdout.write('=====================================================\\n')\n",
    "\n",
    "    # Microphone as stream: Can change this to other stream source\n",
    "    with mic_manager as stream:\n",
    "\n",
    "        while not stream.closed:\n",
    "            sys.stdout.write(YELLOW)\n",
    "            sys.stdout.write('\\n' + str(\n",
    "                STREAMING_LIMIT * stream.restart_counter) + ': NEW REQUEST\\n')\n",
    "\n",
    "            stream.audio_input = []\n",
    "            audio_generator = stream.generator()\n",
    "\n",
    "            requests = (speech.types.StreamingRecognizeRequest(\n",
    "                audio_content=content)for content in audio_generator)\n",
    "\n",
    "            responses = client.streaming_recognize(streaming_config,\n",
    "                                                   requests)\n",
    "\n",
    "            # Now, put the transcription responses to use.\n",
    "            t2s_df= listen_print_loop(responses, stream)\n",
    "\n",
    "            if stream.result_end_time > 0:\n",
    "                stream.final_request_end_time = stream.is_final_end_time\n",
    "            stream.result_end_time = 0\n",
    "            stream.last_audio_input = []\n",
    "            stream.last_audio_input = stream.audio_input\n",
    "            stream.audio_input = []\n",
    "            stream.restart_counter = stream.restart_counter + 1\n",
    "\n",
    "            if not stream.last_transcript_was_final:\n",
    "                sys.stdout.write('\\n')\n",
    "            stream.new_stream = True\n",
    "#             return t2s_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()\n",
    "\n",
    "# [END speech_transcribe_infinite_streaming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
