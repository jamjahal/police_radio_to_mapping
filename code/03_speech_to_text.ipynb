{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --user google.cloud\n",
    "# ! pip install --user google.cloud.speech\n",
    "# pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from multiprocessing.dummy import Pool\n",
    "import live2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/Users/allanshomefolder/.ssh/EmergencyLocator-4d510abe556a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\u001b[0;33m\n",
      "Listening, say \"Quit\" or \"Exit\" to stop.\n",
      "\n",
      "End (ms)       Transcript Results/Status\n",
      "=====================================================\n",
      "\u001b[0;33m\n",
      "0: NEW REQUEST\n",
      "\n",
      "\u001b[0;33m\n",
      "10000: NEW REQUEST\n",
      "\u001b[0;32m\u001b[K41890: check check still going\n",
      "\u001b[0;33m\n",
      "20000: NEW REQUEST\n",
      "\u001b[0;32m\u001b[K48413: check check the still going\n",
      "\u001b[0;31m\u001b[K50763:  exit\n",
      "\u001b[0;33m\n",
      "30000: NEW REQUEST\n",
      "\u001b[0;32m\u001b[K29295: exit\n",
      "\u001b[0;33mExiting...\n"
     ]
    }
   ],
   "source": [
    "df_live = live2text.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/Pickles/streets.pkl\", \"rb\") as fp:\n",
    "    streets = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool is a class in the multiprocessing package that distributes functionality across multiple processes in a computer. Simply put, it lets the computer assign more than one person to build a fence instead of 1. This dramatically speeds up the time it takes for computationally expensive tasks to run and it called and placed around such tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/allanshomefolder/.ssh/EmergencyLocator-4d510abe556a.json\"\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J's Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google's Live Audio Speech To Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4111656f2eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Loads the audio into memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognitionAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_name' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "# file_name = os.path.join(\n",
    "#     os.path.dirname(\"https://tunein.com/radio/San-Francisco-49ers-s275697/\"),\n",
    "#     'resources',\n",
    "#     'audio.raw')\n",
    "import urllib\n",
    "\n",
    "testfile = urllib.URLopener()\n",
    "testfile.retrieve(\"https://tunein.com/radio/San-Francisco-49ers-s275697/\", \"/tmp/index.txt\")\n",
    "filename = \"https://tunein.com/radio/San-Francisco-49ers-s275697/\"\n",
    "\n",
    "# Loads the audio into memory\n",
    "with io.open(file_name) as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code='en-US')\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config, \"https://tunein.com/radio/San-Francisco-49ers-s275697/\")\n",
    "\n",
    "for result in response.results:\n",
    "    print('Transcript: {}'.format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'parts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b6e4e9f6df92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parts/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'parts/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"/Users/allanshomefolder/keys/EmergencyLocator-4d510abe556a.json\") as f:\n",
    "    GOOGLE_CLOUD_SPEECH_CREDENTIALS = f.read()\n",
    "\n",
    "r = sr.Recognizer()\n",
    "files = sorted(os.listdir('parts/'))\n",
    "\n",
    "all_text = []\n",
    "\n",
    "for f in tqdm(files):\n",
    "    name = \"parts/\" + f\n",
    "    # Load audio file\n",
    "    with sr.AudioFile(name) as source:\n",
    "        audio = r.record(source)\n",
    "    # Transcribe audio file\n",
    "    text = r.recognize_google_cloud(audio, credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS)\n",
    "    all_text.append(text)\n",
    "\n",
    "transcript = \"\"\n",
    "for i, t in enumerate(all_text):\n",
    "    total_seconds = i * 30\n",
    "    # Cool shortcut from:\n",
    "    # https://stackoverflow.com/questions/775049/python-time-seconds-to-hms\n",
    "    # to get hours, minutes and seconds\n",
    "    m, s = divmod(total_seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "\n",
    "    # Format time as h:m:s - 30 seconds of text\n",
    "    transcript = transcript + \"{:0>2d}:{:0>2d}:{:0>2d} {}\\n\".format(h, m, s, t)\n",
    "\n",
    "print(transcript)\n",
    "\n",
    "with open(\"transcript.txt\", \"w\") as f:\n",
    "    f.write(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import threading\n",
    "from six.moves import queue\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1a5e74e6975d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mstart_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebsockets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_server\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import threading\n",
    "from six.moves import queue\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import types\n",
    "\n",
    "\n",
    "IP = '0.0.0.0'\n",
    "PORT = 8000\n",
    "\n",
    "class Transcoder(object):\n",
    "    \"\"\"\n",
    "    Converts audio chunks to text\n",
    "    \"\"\"\n",
    "    def __init__(self, encoding, rate, language):\n",
    "        self.buff = queue.Queue()\n",
    "        self.encoding = encoding\n",
    "        self.language = language\n",
    "        self.rate = rate\n",
    "        self.closed = True\n",
    "        self.transcript = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start up streaming speech call\"\"\"\n",
    "        threading.Thread(target=self.process).start()\n",
    "\n",
    "    def response_loop(self, responses):\n",
    "        \"\"\"\n",
    "        Pick up the final result of Speech to text conversion\n",
    "        \"\"\"\n",
    "        for response in responses:\n",
    "            if not response.results:\n",
    "                continue\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "            transcript = result.alternatives[0].transcript\n",
    "            if result.is_final:\n",
    "                self.transcript = transcript\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Audio stream recognition and result parsing\n",
    "        \"\"\"\n",
    "        #You can add speech contexts for better recognition\n",
    "        cap_speech_context = types.SpeechContext(phrases=[\"Add your phrases here\"])\n",
    "        client = speech.SpeechClient()\n",
    "        config = types.RecognitionConfig(\n",
    "            encoding=self.encoding,\n",
    "            sample_rate_hertz=self.rate,\n",
    "            language_code=self.language,\n",
    "            speech_contexts=[cap_speech_context,],\n",
    "            model='command_and_search'\n",
    "        )\n",
    "        streaming_config = types.StreamingRecognitionConfig(\n",
    "            config=config,\n",
    "            interim_results=False,\n",
    "            single_utterance=False)\n",
    "        audio_generator = self.stream_generator()\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "        try:\n",
    "            self.response_loop(responses)\n",
    "        except:\n",
    "            self.start()\n",
    "\n",
    "    def stream_generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self.buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self.buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            yield b''.join(data)\n",
    "\n",
    "    def write(self, data):\n",
    "        \"\"\"\n",
    "        Writes data to the buffer\n",
    "        \"\"\"\n",
    "        self.buff.put(data)\n",
    "\n",
    "\n",
    "async def audio_processor(websocket, path):\n",
    "    \"\"\"\n",
    "    Collects audio from the stream, writes it to buffer and return the output of Google speech to text\n",
    "    \"\"\"\n",
    "    config = await websocket.recv()\n",
    "    if not isinstance(config, str):\n",
    "        print(\"ERROR, no config\")\n",
    "        return\n",
    "    config = json.loads(config)\n",
    "    transcoder = Transcoder(\n",
    "        encoding=config[\"format\"],\n",
    "        rate=config[\"rate\"],\n",
    "        language=config[\"language\"]\n",
    "    )\n",
    "    transcoder.start()\n",
    "    while True:\n",
    "        try:\n",
    "            data = await websocket.recv()\n",
    "        except websockets.ConnectionClosed:\n",
    "            print(\"Connection closed\")\n",
    "            break\n",
    "        transcoder.write(data)\n",
    "        transcoder.closed = False\n",
    "        if transcoder.transcript:\n",
    "            print(transcoder.transcript)\n",
    "            await websocket.send(transcoder.transcript)\n",
    "            transcoder.transcript = None\n",
    "\n",
    "start_server = websockets.serve(audio_processor, IP, PORT)\n",
    "asyncio.get_event_loop().run_until_complete(start_server)\n",
    "asyncio.get_event_loop().run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.get_event_loop().stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than opening an audio file to create the stream (as on line 34 of that example), \n",
    "# pass the stream directly to the audio sample object (as on line 36)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../audio_data/audio_files/wav_files/10904-20190730-1657_24.wav',\n",
       " '../audio_data/audio_files/wav_files/10904-20190730-1657_31.wav',\n",
       " '../audio_data/audio_files/wav_files/10904-20190730-1657_23.wav']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../audio_data/audio_files/wav_files/'\n",
    "wav_file = []\n",
    "for filename in os.listdir(path)[1:]:\n",
    "    wav_file.append(path + filename)\n",
    "wav_file[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google’s Speech to Text API accepts a wav file and stores it into memory. When calling the speech to text API, we can pass in a dictionary for it to reference its results on. We decided to run the API with and without street context to see if which setting would provide better results. The API then proceeds to detect speech in the audio file and return a transcription of what it heard and it’s confidence in the results. We returned those results as a dataframe. \n",
    "\n",
    "## With Street Name Context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_context(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\",\n",
    "\n",
    "        speech_contexts = [{\n",
    "                        \"phrases\": np.random.choice(streets, 5000)\n",
    "                         }]\n",
    "    )\n",
    "    \n",
    "    # Streaming config\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        single_utterance=True,\n",
    "        interim_results =True)\n",
    "    \n",
    "    #Detects speech in audio file\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(1)\n",
    "    return transcript, confidence, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: oauth2.googleapis.com\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "                                         transcripts  confidence\n",
      "0              Market 1130 Highway Street 1 1 3 0 hi    0.646961\n",
      "1  Ester Drive robson's plane set the driver knoc...    0.797990\n",
      "2                                          powers of    0.584350\n",
      "3                                     is going to be    0.461068\n",
      "4       our brothers are critical for 1636 thank you    0.870915\n",
      "5  Grant or kind of somebody can pray Sac State f...    0.698791\n",
      "6                        Peridot we close races here    0.826199\n",
      "7  Library 612 Smithfield Street between 6th Aven...    0.749222\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts_context = pool.map(speech_to_text_context, wav_file)\n",
    "\n",
    "captions_context = [a[0] for a in list_of_transcripts_context if a[0] != '']\n",
    "confidence_context = [a[1] for a in list_of_transcripts_context if a[0] != '']\n",
    "\n",
    "data_context = {'transcripts': captions_context, \n",
    "                'confidence': confidence_context}\n",
    "df_context = pd.DataFrame(data_context)\n",
    "# df_context.to_csv('../data/Data/transcribed_radio_with_street_context.csv')\n",
    "print(df_context.head(25))\n",
    "    \n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Peridot we close races here</td>\n",
       "      <td>0.826199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Market 1130 Highway Street 1 1 3 0 hi</td>\n",
       "      <td>0.646961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>powers of</td>\n",
       "      <td>0.584350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Grant or kind of somebody can pray Sac State f...</td>\n",
       "      <td>0.698791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>is going to be</td>\n",
       "      <td>0.461068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ester Drive robson's plane set the driver knoc...</td>\n",
       "      <td>0.797990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transcripts  confidence\n",
       "6                        Peridot we close races here    0.826199\n",
       "0              Market 1130 Highway Street 1 1 3 0 hi    0.646961\n",
       "2                                          powers of    0.584350\n",
       "5  Grant or kind of somebody can pray Sac State f...    0.698791\n",
       "3                                     is going to be    0.461068\n",
       "1  Ester Drive robson's plane set the driver knoc...    0.797990"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_context.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162156812846661"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_context['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Street Name Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\"\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file    \n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return transcript, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7a10c75ae35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m data = {'transcripts': captions, \n",
      "\u001b[0;32m<ipython-input-61-7a10c75ae35f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_transcripts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m data = {'transcripts': captions, \n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts = pool.map(speech_to_text, wav_file)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "captions = [a[0] for a in list_of_transcripts if a[0] != '']\n",
    "confidence = [a[1] for a in list_of_transcripts if a[0] != '']\n",
    "names = [a[2] for a in list_of_transcripts if a[0] != '']\n",
    "\n",
    "data = {'transcripts': captions, \n",
    "        'confidence': confidence}\n",
    "df = pd.DataFrame(data)\n",
    "# df.to_csv('../data/Data/transcribed_radio.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7311672965685526"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Code adapted from [NY General Assembly DSI radio-to-location repository](https://github.com/mchbmn/radio-to-location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
